{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ABOUT THE DATASET**\n",
    "\n",
    "HAM10000 (\"Human Against Machine with 10000 training images\") dataset - a large collection of multi-source dermatoscopic images of pigmented lesions\n",
    "\n",
    "The dermatoscopic images are collected from different populations, acquired and stored by different modalities. The final dataset consists of 10015 dermatoscopic images.\n",
    "\n",
    "It has 7 different classes of skin cancer which are listed below :\n",
    "- Melanocytic nevi\n",
    "- Melanoma\n",
    "- Benign keratosis-like lesions\n",
    "- Basal cell carcinoma\n",
    "- Actinic keratoses\n",
    "- Vascular lesions\n",
    "- Dermatofibroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, isnull\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# Importing required libraries for neural network training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Skin Cancer MNIST\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAM10000_metadata.csv file is the main csv file that includes the data of all training images, the features of which are -\n",
    " \n",
    "1. Lesion_id\n",
    "2. Image_id\n",
    "3. save Dx\n",
    "4. Dx_type\n",
    "5. Age\n",
    "6. Sex\n",
    "7. Localization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from HAM_metadata.csv\n",
    "df = spark.read.csv('../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of each column\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general statistical analysis of the numerical values of dataset (here : age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for numerical columns\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([col(c).isNull().cast(\"int\").alias(c) for c in df.columns]).agg(*[sum(c).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf = df.toPandas()\n",
    "sns.displot(pdf['age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = pdf['age'].median()\n",
    "df = df.withColumn('age', when(isnull(col('age')), median_age).otherwise(col('age')))\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([col(c).isNull().cast(\"int\").alias(c) for c in df.columns]).agg(*[sum(c).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesion type dictionary\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "# Base directory for skin images\n",
    "base_skin_dir = '../input/skin-cancer-mnist-ham10000'\n",
    "\n",
    "# Merge images from both folders into one dictionary\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['path'] = pdf['image_id'].map(imageid_path_dict.get)\n",
    "pdf['cell_type'] = pdf['dx'].map(lesion_type_dict.get)\n",
    "pdf['cell_type_idx'] = pd.Categorical(pdf['cell_type']).codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "Resizing of images because the original dimensions of 450 * 600 * 3 take long time to process in Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['image'] = pdf['path'].map(lambda x: np.asarray(Image.open(x).resize((125, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "# Create a plot with 7 rows and n_samples columns\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize=(4 * n_samples, 3 * 7))\n",
    "\n",
    "# Group by cell type and plot images\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, pdf.sort_values(['cell_type']).groupby('cell_type')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=2018).iterrows()):\n",
    "        c_ax.imshow(c_row['image'])\n",
    "        c_ax.axis('off')\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('category_samples.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image size distribution\n",
    "image_size_counts = pdf['image'].map(lambda x: x.shape).value_counts()\n",
    "print(image_size_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**\n",
    "Exploratory data analysis can help detect obvious errors, identify outliers in datasets, understand relationships, unearth important factors, find patterns within data, and provide new insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(left=0.125, bottom=1, right=0.9, top=2, hspace=0.2)\n",
    "plt.subplot(2,4,1)\n",
    "plt.title(\"AGE\",fontsize=15)\n",
    "plt.ylabel(\"Count\")\n",
    "pdf['age'].value_counts().plot.bar()\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "plt.title(\"GENDER\",fontsize=15)\n",
    "plt.ylabel(\"Count\")\n",
    "pdf['sex'].value_counts().plot.bar()\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "plt.title(\"localization\",fontsize=15)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "pdf['localization'].value_counts().plot.bar()\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "plt.title(\"CELL TYPE\",fontsize=15)\n",
    "plt.ylabel(\"Count\")\n",
    "pdf['cell_type'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Skin diseases are found to be maximum in people aged around 45. Minimum for 10 and below. We also observe that the probability of having skin disease increases with the increase in age.\n",
    "2. Skin diseases are more prominent in Men as compared to Women and other gender.\n",
    "3. Skin diseases are more visible on the \"back\" of the body and least on the \"acral surfaces\"(such as limbs, fingers, or ears).\n",
    "4. The most found disease among people is Melanocytic nevi while the least found is Dermatofibroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1,2,1)\n",
    "pdf['dx'].value_counts().plot.pie(autopct=\"%1.1f%%\")\n",
    "plt.subplot(1,2,2)\n",
    "pdf['dx_type'].value_counts().plot.pie(autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Type of skin disease:\n",
    "    *     nv: Melanocytic nevi - 69.9%\n",
    "    *     mel: Melanoma - 11.1 %\n",
    "    *     bkl: Benign keratosis-like lesions - 11.0%\n",
    "    *     bcc: Basal cell carcinoma - 5.1%\n",
    "    *     akiec: Actinic keratoses- 3.3%\n",
    "    *     vasc: Vascular lesions-1.4%\n",
    "    *     df: Dermatofibroma - 1.1%\n",
    "\n",
    "2. How the skin disease was discovered:\n",
    "   * histo - histopathology - 53.3%\n",
    "   * follow_up - follow up examination - 37.0%\n",
    "   * consensus - expert consensus - 9.0%\n",
    "   * confocal - confirmation by in-vivo confocal microscopy - 0.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.title('LOCALIZATION VS GENDER',fontsize = 15)\n",
    "sns.countplot(y='localization', hue='sex',data=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Back are is the most affected among people and more prominent in men.\n",
    "* Infection on Lower extremity of the body is more visible in women.\n",
    "* Some unknown regions also show infections and it's visible in men, women and other genders.\n",
    "* The acral surfaces show the least infection cases that too in men only. Other gender groups don't show this kind of infection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.title('LOCALIZATION VS CELL TYPE',fontsize = 15)\n",
    "sns.countplot(y='localization', hue='cell_type',data=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The face is infected the most by Benign keratosis-like lesions.\n",
    "* Body parts(except face) are infected the most by Melanocytic nevi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.subplot(131)\n",
    "plt.title('AGE VS CELL TYPE',fontsize = 15)\n",
    "sns.countplot(y='age', hue='cell_type',data=pdf)\n",
    "plt.subplot(132)\n",
    "plt.title('GENDER VS CELL TYPE',fontsize = 15)\n",
    "sns.countplot(y='sex', hue='cell_type',data=pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The age group between 0-75 years is infected the most by Melanocytic nevi. On the other hand, the people aged 80-90 are affected more by Benign keratosis-like lesions.\n",
    "\n",
    "2. All the gender groups are affected the most by Melanocytic nevi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitting into features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'cell_type_idx' column to get features and target\n",
    "features = pdf.drop(columns=['cell_type_idx'], axis=1)\n",
    "target = pdf['cell_type_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitting into training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.25, random_state=666)\n",
    "print(pd.unique(x_train_o['cell_type'].values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization or Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'image' column to numpy arrays\n",
    "x_train = np.asarray(x_train_o['image'].tolist())\n",
    "x_test = np.asarray(x_test_o['image'].tolist())\n",
    "\n",
    "# Calculate mean and standard deviation for normalization\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_test_mean) / x_test_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform one-hot encoding on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_o, num_classes=7)\n",
    "y_test = to_categorical(y_test_o, num_classes=7)\n",
    "y_train_o.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.1, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to the required dimensions\n",
    "x_train = x_train.reshape(x_train.shape[0], *(100, 125, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(100, 125, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(100, 125, 3))\n",
    "\n",
    "# Flatten the images for Dense layer input\n",
    "x_train = x_train.reshape(x_train.shape[0], 125 * 100 * 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 125 * 100 * 3)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], 125 * 100 * 3)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, kernel_initializer='uniform', activation='relu', input_dim=37500))\n",
    "model.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=7, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00075, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "# Compile the Keras model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the Keras model on the dataset\n",
    "history = model.fit(x_train, y_train, batch_size=10, epochs=18, validation_data=(x_validate, y_validate))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\n",
    "print(\"Test: accuracy = \", accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "input_shape = (100, 125, 3)\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same', input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.16))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=4, verbose=1, factor=0.5, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.12,\n",
    "    height_shift_range=0.12,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model\n",
    "epochs = 60\n",
    "batch_size = 64\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs, validation_data=(x_validate, y_validate),\n",
    "                    verbose=1, steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
    "print(f\"Validation: accuracy = {accuracy_v*100:.2f}%  ;  loss_v = {loss_v:.4f}\")\n",
    "print(f\"Test: accuracy = {accuracy*100:.2f}%  ;  loss = {loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plot the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix and Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix    \n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_validate)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "Y_true = np.argmax(y_validate, axis=1)\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(7))\n",
    "\n",
    "# Predict the values from the test dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(7))\n",
    "\n",
    "# Error analysis\n",
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
    "plt.bar(np.arange(7), label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
